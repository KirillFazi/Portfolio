{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «киВшоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Описание проекта"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Твиишоп» запускает новый сервис. Добавили функцию редактирования и дополнения описания товаров. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужна модель, которая будет определять токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Описание данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Для повторения проекта, можно использовать открытый датасет с kaggle: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data*\n",
    "\n",
    "- `text` - текст комментария\n",
    "- `toxic` - целевой признак (1 - токсичный комментарий, 0 - нет)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:22:46.526729Z",
     "start_time": "2023-04-28T18:22:46.511083Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Embedding, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import  AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:49.573919Z",
     "start_time": "2023-04-28T13:27:41.224095Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим подвыборку из n строк, чтобы ускорить подбор кодировки и выбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:49.588952Z",
     "start_time": "2023-04-28T13:27:49.574927Z"
    }
   },
   "outputs": [],
   "source": [
    "# make small sample\n",
    "# data = data.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:49.656720Z",
     "start_time": "2023-04-28T13:27:49.590493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим лишний столбец с индексами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:49.670273Z",
     "start_time": "2023-04-28T13:27:49.623931Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop Unnamed: 0 column\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим сколько строк и проверим на пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:49.787869Z",
     "start_time": "2023-04-28T13:27:49.646695Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:49.932720Z",
     "start_time": "2023-04-28T13:27:49.693602Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается сильный дисбаланс классов. При обучении моделей, нужно будет это учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем токенизатор и модель для кодировки текста. Будем использовать unitary/toxic-bert (основанная на DistilBert), так как он специально обучен для задачи классификации токсичности комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:27:56.397180Z",
     "start_time": "2023-04-28T13:27:49.708147Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"unitary/toxic-bert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем текст и записываем в переменную tokenized. Выводим размер токенизированного текста на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:29:08.242830Z",
     "start_time": "2023-04-28T13:27:56.344185Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = data['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True)))\n",
    "tokenized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем векторы одинаковой длины, заполняя недостающие значения нулями. И создаем маску векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T13:29:17.124819Z",
     "start_time": "2023-04-28T13:29:08.244848Z"
    }
   },
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(512-len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производим создание эмбеддингов, с помощью предобученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:17:44.914829Z",
     "start_time": "2023-04-28T13:29:17.128818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f10e5e1114341ff92f4bc83ee7ed30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 250\n",
    "embeddings = []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size + 1)):\n",
    "    batch = torch.tensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.tensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch.to(device), attention_mask=attention_mask_batch.to(device))\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем список в двумерную матрицу. И сохраняем в переменную embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:17:45.363802Z",
     "start_time": "2023-04-28T14:17:44.918805Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем ячейку для сохранения эмбеддингов в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings\n",
    "# embeddings_df = pd.DataFrame(embeddings)\n",
    "# embeddings_df.to_parquet('embeddings_toxic-comment-model.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем ячейку для загрузки эмбеддингов из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:17:58.790313Z",
     "start_time": "2023-04-28T14:17:58.748314Z"
    }
   },
   "outputs": [],
   "source": [
    "# load embeddings\n",
    "# embeddings = pd.read_parquet('embeddings_distilBert.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размерность эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую, валидационную и тестовую выборки. Соотношение 75/25/10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:17:59.178758Z",
     "start_time": "2023-04-28T14:17:58.782314Z"
    }
   },
   "outputs": [],
   "source": [
    "# split data on train, valid and test\n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(embeddings, data['toxic'], test_size=0.1, random_state=42, stratify=data['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:17:59.587659Z",
     "start_time": "2023-04-28T14:17:59.179759Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.3, random_state=42, stratify=y_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим размерность выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:17:59.602658Z",
     "start_time": "2023-04-28T14:17:59.589640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((143362, 768), (143362,)),\n",
       " ((100353, 768), (100353,)),\n",
       " ((43009, 768), (43009,)),\n",
       " ((15930, 768), (15930,)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_valid.shape, y_train_valid.shape), (X_train.shape, y_train.shape), (X_valid.shape, y_valid.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель LogisticRegression с проверкой threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:18:53.491822Z",
     "start_time": "2023-04-28T14:17:59.607641Z"
    }
   },
   "outputs": [],
   "source": [
    "# train logistic regression\n",
    "lr = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Obtain predicted probabilities on the test set\n",
    "probas = lr.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# Define a range of threshold values\n",
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Evaluate the model performance for each threshold value\n",
    "for threshold in thresholds:\n",
    "    y_pred = (probas >= threshold).astype(int)\n",
    "    precision = precision_score(y_valid, y_pred)\n",
    "    recall = recall_score(y_valid, y_pred)\n",
    "    f1 = f1_score(y_valid, y_pred)\n",
    "    print(f\"Threshold: {threshold:.1f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Threshold: 0.1, Precision: 0.86, Recall: 0.98, F1-score: 0.92\n",
    "- Threshold: 0.2, Precision: 0.90, Recall: 0.98, F1-score: 0.94\n",
    "- Threshold: 0.3, Precision: 0.92, Recall: 0.97, F1-score: 0.94\n",
    "- Threshold: 0.4, Precision: 0.94, Recall: 0.96, F1-score: 0.95\n",
    "- Threshold: 0.5, Precision: 0.95, Recall: 0.95, F1-score: 0.95\n",
    "- Threshold: 0.6, Precision: 0.96, Recall: 0.93, F1-score: 0.94\n",
    "- Threshold: 0.7, Precision: 0.97, Recall: 0.91, F1-score: 0.94\n",
    "- Threshold: 0.8, Precision: 0.98, Recall: 0.89, F1-score: 0.93\n",
    "- Threshold: 0.9, Precision: 0.99, Recall: 0.84, F1-score: 0.91"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы можем видеть, при threshold = 0.5, мы получаем наилучший результат. Значит, не стоит менять threshold и делать баланс классов в других моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель LightGBM с подбором гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T16:25:57.198279Z",
     "start_time": "2023-04-28T16:21:19.418110Z"
    }
   },
   "outputs": [],
   "source": [
    "# train lightgbm\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [8, 10 , 12],\n",
    "    'learning_rate': [0.05, 0.1, 0.15]\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(lgbm, param_grid, cv=2, scoring='f1', random_state=42, n_jobs=-1)\n",
    "grid_search.fit(X_train_valid, y_train_valid)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(f'F1-score for LightGBM: {grid_search.best_score_:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.1}\n",
    "\n",
    "F1-score for LightGBM: 0.94"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:54:00.049419Z",
     "start_time": "2023-04-28T17:53:43.539704Z"
    }
   },
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state=42, **grid_search.best_params_)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm.predict(X_valid)\n",
    "print(f'F1-score for LightGBM: {f1_score(y_valid, y_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "F1-score for LightGBM: 0.94\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:19:19.364217Z",
     "start_time": "2023-04-28T14:19:19.293906Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:55:31.226949Z",
     "start_time": "2023-04-28T14:51:30.999489Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2277cb1b4f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(128, activation='relu', input_shape=(768,)))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(128, activation='relu'))\n",
    "nn.add(Dropout(0.2))\n",
    "nn.add(Dense(64, activation='relu'))\n",
    "nn.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "nn.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=[get_f1])\n",
    "\n",
    "nn.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=150,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStopping(monitor='val_f1_score', mode='max', patience=5, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "F1-score for Neural Network: 0.93"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все модели показали хороший результат. Лучшей моделью оказалась LogisticRegression. Нужно проверить не переобучилась ли она на тренировочных данных. И для сравнения проверим все остальные модели. Также, сравним результаты с константной моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:04:38.548471Z",
     "start_time": "2023-04-28T18:04:38.470327Z"
    }
   },
   "outputs": [],
   "source": [
    "# test constant model\n",
    "dummy = DummyClassifier(strategy='constant', constant=1)\n",
    "dummy.fit(X_train, y_train)\n",
    "print(f'F1 score for DummyClassifier: {f1_score(y_test, dummy.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "F1 score for DummyClassifier: 0.18451193800216537\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T14:49:46.653404Z",
     "start_time": "2023-04-28T14:49:46.558923Z"
    }
   },
   "outputs": [],
   "source": [
    "# test logistic regression\n",
    "print(f'F1 score for LogisticRegression: {f1_score(y_test, lr.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "F1 score for LogisticRegression: 0.9499539453484802\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:54:16.302654Z",
     "start_time": "2023-04-28T17:54:16.053170Z"
    }
   },
   "outputs": [],
   "source": [
    "# test lightgbm\n",
    "print(f'F1 score for LGBMClassifier: {f1_score(y_test, lgbm.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "F1 score for LGBMClassifier: 0.9474976972674239\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T15:31:18.357168Z",
     "start_time": "2023-04-28T15:31:17.292993Z"
    }
   },
   "outputs": [],
   "source": [
    "# test neural network\n",
    "print(f'F1 score for Neural Network: {nn.evaluate(X_test, y_test)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "498/498 [==============================] - 1s 2ms/step - loss: 0.0288 - get_f1: 0.9252\n",
    "\n",
    "\n",
    "F1 score for Neural Network: 0.9251944422721863\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все модели имеют высокий показатель F1-меры и он почти равен на вариационных данных. Также, по сравнению с константным предсказанием наши модели показывают отличный результат. Из этого можно сделать вывод, что модели не переобучились и дают адекватные предсказания. Обучим LogisticRegression на всех данных и снова проверим ее на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T17:57:21.766294Z",
     "start_time": "2023-04-28T17:55:54.889602Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42, solver='liblinear')\n",
    "lr.fit(X_train_valid, y_train_valid);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T18:00:55.059683Z",
     "start_time": "2023-04-28T18:00:54.958927Z"
    }
   },
   "outputs": [],
   "source": [
    "# test logistic regression with train and valid data\n",
    "print(f'F1 score for LogisticRegression: {f1_score(y_test, lr.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "F1 score for LogisticRegression: 0.9504767763764994\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе работы были выполнены следующие шаги:\n",
    "\n",
    "- Данные были загружены и подготовлены для обучения моделей.\n",
    "- Были обучены модели LogisticRegression, LGBMClassifier, Neural Network.\n",
    "- Были проведены тесты моделей на тестовых данных.\n",
    "- Были сделаны выводы по результатам тестов.\n",
    "\n",
    "В результате работы была достигнута F1-мера не менее 0.75. А если быть точным то 0.95. Также, было обнаружено, что модели не переобучились и дают адекватные предсказания. Адекватность модели проверялась сравнением с константной моделью. Также, было обнаружено, что модель LogisticRegression показала лучший результат. Поэтому, она была обучена на всех данных и проверена на тестовых данных. И она показала отличный результат. F1-мера на тестовых данных составила 0.95. Поэтому можно сделать вывод, что модель LogisticRegression может быть использована для предсказания токсичности комментариев."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
